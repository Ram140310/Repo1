{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas==0.25.3\n",
    "!pip install numpy==1.17.3\n",
    "!pip install Keras==2.3.1\n",
    "!pip install tensorflow==2.0.0\n",
    "!pip install tqdm==4.43.0\n",
    "!pip install matplotlib==3.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def create_unique_word_dict(text:list) -> dict:\n",
    "    \"\"\"\n",
    "    A method that creates a dictionary where the keys are unique words\n",
    "    and key values are indices\n",
    "    \"\"\"\n",
    "    # Getting all the unique words from our text and sorting them alphabetically\n",
    "    words = list(set(text))\n",
    "    words.sort()\n",
    "\n",
    "    # Creating the dictionary for the unique words\n",
    "    unique_word_dict = {}\n",
    "    for i, word in enumerate(words):\n",
    "        unique_word_dict.update({\n",
    "            word: i\n",
    "        })\n",
    "    print(unique_word_dict)\n",
    "    return unique_word_dict    \n",
    "\n",
    "def text_preprocessing(\n",
    "    text:list,\n",
    "    punctuations = r'''!()-[]{};:'\"\\,<>./?@#$%^&*_â€œ~''',\n",
    "    stop_words=['and', 'a', 'is', 'the', 'in', 'be', 'will']\n",
    "    )->list:\n",
    "    \"\"\"\n",
    "    A method to preproces text\n",
    "    \"\"\"\n",
    "    for x in text.lower(): \n",
    "        if x in punctuations: \n",
    "            text = text.replace(x, \"\")\n",
    "\n",
    "    # Removing words that have numbers in them\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "\n",
    "    # Removing digits\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "\n",
    "    # Cleaning the whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Setting every word to lower\n",
    "    text = text.lower()\n",
    "\n",
    "    # Converting all our text to a list \n",
    "    text = text.split(' ')\n",
    "\n",
    "    # Droping empty strings\n",
    "    text = [x for x in text if x!='']\n",
    "\n",
    "    # Droping stop words\n",
    "    text = [x for x in text if x not in stop_words]\n",
    "\n",
    "    return text\n",
    "\n",
    "# Functions to find the most similar word \n",
    "def euclidean(vec1:np.array, vec2:np.array) -> float:\n",
    "    \"\"\"\n",
    "    A function to calculate the euclidean distance between two vectors\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((vec1 - vec2)**2))\n",
    "\n",
    "def find_similar(word:str, embedding_dict:dict, top_n=10)->list:\n",
    "    \"\"\"\n",
    "    A method to find the most similar word based on the learnt embeddings\n",
    "    \"\"\"\n",
    "    dist_dict = {}\n",
    "    word_vector = embedding_dict.get(word, [])\n",
    "    if len(word_vector) > 0:\n",
    "        for key, value in embedding_dict.items():\n",
    "            if key!=word:\n",
    "                dist = euclidean(word_vector, value)\n",
    "                dist_dict.update({\n",
    "                    key: dist\n",
    "                })\n",
    "\n",
    "        return sorted(dist_dict.items(), key=lambda x: x[1])[0:top_n]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The future king is the prince',\n",
       " 'Daughter is the princess ',\n",
       " 'Son is the prince',\n",
       " 'Only a man can be a king ',\n",
       " 'Only a woman can be a queen',\n",
       " 'The princess will be a queen',\n",
       " 'Queen and king rule the realm',\n",
       " 'The prince is a strong man',\n",
       " 'The princess is a beautiful woman ',\n",
       " 'The royal family is the king and queen and their children',\n",
       " 'Prince is only a boy now',\n",
       " 'A boy will be a man']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['future', 'king', 'prince']\n",
      "......i..... 0 ....word.... future\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 1 ....word.... king\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 2 ....word.... prince\n",
      "0\n",
      "1\n",
      "2\n",
      "['daughter', 'princess']\n",
      "......i..... 0 ....word.... daughter\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 1 ....word.... princess\n",
      "0\n",
      "1\n",
      "2\n",
      "['son', 'prince']\n",
      "......i..... 0 ....word.... son\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 1 ....word.... prince\n",
      "0\n",
      "1\n",
      "2\n",
      "['only', 'man', 'can', 'king']\n",
      "......i..... 0 ....word.... only\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 1 ....word.... man\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 2 ....word.... can\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 3 ....word.... king\n",
      "0\n",
      "1\n",
      "2\n",
      "['only', 'woman', 'can', 'queen']\n",
      "......i..... 0 ....word.... only\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 1 ....word.... woman\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 2 ....word.... can\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 3 ....word.... queen\n",
      "0\n",
      "1\n",
      "2\n",
      "['princess', 'queen']\n",
      "......i..... 0 ....word.... princess\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 1 ....word.... queen\n",
      "0\n",
      "1\n",
      "2\n",
      "['queen', 'king', 'rule', 'realm']\n",
      "......i..... 0 ....word.... queen\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 1 ....word.... king\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 2 ....word.... rule\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 3 ....word.... realm\n",
      "0\n",
      "1\n",
      "2\n",
      "['prince', 'strong', 'man']\n",
      "......i..... 0 ....word.... prince\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 1 ....word.... strong\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 2 ....word.... man\n",
      "0\n",
      "1\n",
      "2\n",
      "['princess', 'beautiful', 'woman']\n",
      "......i..... 0 ....word.... princess\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 1 ....word.... beautiful\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 2 ....word.... woman\n",
      "0\n",
      "1\n",
      "2\n",
      "['royal', 'family', 'king', 'queen', 'their', 'children']\n",
      "......i..... 0 ....word.... royal\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 1 ....word.... family\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 2 ....word.... king\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 3 ....word.... queen\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 4 ....word.... their\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 5 ....word.... children\n",
      "0\n",
      "1\n",
      "2\n",
      "['prince', 'only', 'boy', 'now']\n",
      "......i..... 0 ....word.... prince\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 1 ....word.... only\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 2 ....word.... boy\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 3 ....word.... now\n",
      "0\n",
      "1\n",
      "2\n",
      "['boy', 'man']\n",
      "......i..... 0 ....word.... boy\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 1 ....word.... man\n",
      "0\n",
      "1\n",
      "2\n",
      "word list  [['future', 'king'], ['future', 'prince'], ['king', 'prince'], ['king', 'future'], ['prince', 'king'], ['prince', 'future'], ['daughter', 'princess'], ['princess', 'daughter'], ['son', 'prince'], ['prince', 'son'], ['only', 'man'], ['only', 'can'], ['only', 'king'], ['man', 'can'], ['man', 'only'], ['man', 'king'], ['can', 'king'], ['can', 'man'], ['can', 'only'], ['king', 'can'], ['king', 'man'], ['king', 'only'], ['only', 'woman'], ['only', 'can'], ['only', 'queen'], ['woman', 'can'], ['woman', 'only'], ['woman', 'queen'], ['can', 'queen'], ['can', 'woman'], ['can', 'only'], ['queen', 'can'], ['queen', 'woman'], ['queen', 'only'], ['princess', 'queen'], ['queen', 'princess'], ['queen', 'king'], ['queen', 'rule'], ['queen', 'realm'], ['king', 'rule'], ['king', 'queen'], ['king', 'realm'], ['rule', 'realm'], ['rule', 'king'], ['rule', 'queen'], ['realm', 'rule'], ['realm', 'king'], ['realm', 'queen'], ['prince', 'strong'], ['prince', 'man'], ['strong', 'man'], ['strong', 'prince'], ['man', 'strong'], ['man', 'prince'], ['princess', 'beautiful'], ['princess', 'woman'], ['beautiful', 'woman'], ['beautiful', 'princess'], ['woman', 'beautiful'], ['woman', 'princess'], ['royal', 'family'], ['royal', 'king'], ['royal', 'queen'], ['family', 'king'], ['family', 'royal'], ['family', 'queen'], ['family', 'their'], ['king', 'queen'], ['king', 'family'], ['king', 'their'], ['king', 'royal'], ['king', 'children'], ['queen', 'their'], ['queen', 'king'], ['queen', 'children'], ['queen', 'family'], ['queen', 'royal'], ['their', 'children'], ['their', 'queen'], ['their', 'king'], ['their', 'family'], ['children', 'their'], ['children', 'queen'], ['children', 'king'], ['prince', 'only'], ['prince', 'boy'], ['prince', 'now'], ['only', 'boy'], ['only', 'prince'], ['only', 'now'], ['boy', 'now'], ['boy', 'only'], ['boy', 'prince'], ['now', 'boy'], ['now', 'only'], ['now', 'prince'], ['boy', 'man'], ['man', 'boy']]\n",
      "{'beautiful': 0, 'boy': 1, 'can': 2, 'children': 3, 'daughter': 4, 'family': 5, 'future': 6, 'king': 7, 'man': 8, 'now': 9, 'only': 10, 'prince': 11, 'princess': 12, 'queen': 13, 'realm': 14, 'royal': 15, 'rule': 16, 'son': 17, 'strong': 18, 'their': 19, 'woman': 20}\n",
      "unique_word_dict {'beautiful': 0, 'boy': 1, 'can': 2, 'children': 3, 'daughter': 4, 'family': 5, 'future': 6, 'king': 7, 'man': 8, 'now': 9, 'only': 10, 'prince': 11, 'princess': 12, 'queen': 13, 'realm': 14, 'royal': 15, 'rule': 16, 'son': 17, 'strong': 18, 'their': 19, 'woman': 20}\n",
      "words ['beautiful', 'boy', 'can', 'children', 'daughter', 'family', 'future', 'king', 'man', 'now', 'only', 'prince', 'princess', 'queen', 'realm', 'royal', 'rule', 'son', 'strong', 'their', 'woman']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98it [00:00, 631.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......i..... 0 ....word_list.... ['future', 'king'] word_list[0] future word_list[1]  king\n",
      "......i..... 1 ....word_list.... ['future', 'prince'] word_list[0] future word_list[1]  prince\n",
      "......i..... 2 ....word_list.... ['king', 'prince'] word_list[0] king word_list[1]  prince\n",
      "......i..... 3 ....word_list.... ['king', 'future'] word_list[0] king word_list[1]  future\n",
      "......i..... 4 ....word_list.... ['prince', 'king'] word_list[0] prince word_list[1]  king\n",
      "......i..... 5 ....word_list.... ['prince', 'future'] word_list[0] prince word_list[1]  future\n",
      "......i..... 6 ....word_list.... ['daughter', 'princess'] word_list[0] daughter word_list[1]  princess\n",
      "......i..... 7 ....word_list.... ['princess', 'daughter'] word_list[0] princess word_list[1]  daughter\n",
      "......i..... 8 ....word_list.... ['son', 'prince'] word_list[0] son word_list[1]  prince\n",
      "......i..... 9 ....word_list.... ['prince', 'son'] word_list[0] prince word_list[1]  son\n",
      "......i..... 10 ....word_list.... ['only', 'man'] word_list[0] only word_list[1]  man\n",
      "......i..... 11 ....word_list.... ['only', 'can'] word_list[0] only word_list[1]  can\n",
      "......i..... 12 ....word_list.... ['only', 'king'] word_list[0] only word_list[1]  king\n",
      "......i..... 13 ....word_list.... ['man', 'can'] word_list[0] man word_list[1]  can\n",
      "......i..... 14 ....word_list.... ['man', 'only'] word_list[0] man word_list[1]  only\n",
      "......i..... 15 ....word_list.... ['man', 'king'] word_list[0] man word_list[1]  king\n",
      "......i..... 16 ....word_list.... ['can', 'king'] word_list[0] can word_list[1]  king\n",
      "......i..... 17 ....word_list.... ['can', 'man'] word_list[0] can word_list[1]  man\n",
      "......i..... 18 ....word_list.... ['can', 'only'] word_list[0] can word_list[1]  only\n",
      "......i..... 19 ....word_list.... ['king', 'can'] word_list[0] king word_list[1]  can\n",
      "......i..... 20 ....word_list.... ['king', 'man'] word_list[0] king word_list[1]  man\n",
      "......i..... 21 ....word_list.... ['king', 'only'] word_list[0] king word_list[1]  only\n",
      "......i..... 22 ....word_list.... ['only', 'woman'] word_list[0] only word_list[1]  woman\n",
      "......i..... 23 ....word_list.... ['only', 'can'] word_list[0] only word_list[1]  can\n",
      "......i..... 24 ....word_list.... ['only', 'queen'] word_list[0] only word_list[1]  queen\n",
      "......i..... 25 ....word_list.... ['woman', 'can'] word_list[0] woman word_list[1]  can\n",
      "......i..... 26 ....word_list.... ['woman', 'only'] word_list[0] woman word_list[1]  only\n",
      "......i..... 27 ....word_list.... ['woman', 'queen'] word_list[0] woman word_list[1]  queen\n",
      "......i..... 28 ....word_list.... ['can', 'queen'] word_list[0] can word_list[1]  queen\n",
      "......i..... 29 ....word_list.... ['can', 'woman'] word_list[0] can word_list[1]  woman\n",
      "......i..... 30 ....word_list.... ['can', 'only'] word_list[0] can word_list[1]  only\n",
      "......i..... 31 ....word_list.... ['queen', 'can'] word_list[0] queen word_list[1]  can\n",
      "......i..... 32 ....word_list.... ['queen', 'woman'] word_list[0] queen word_list[1]  woman\n",
      "......i..... 33 ....word_list.... ['queen', 'only'] word_list[0] queen word_list[1]  only\n",
      "......i..... 34 ....word_list.... ['princess', 'queen'] word_list[0] princess word_list[1]  queen\n",
      "......i..... 35 ....word_list.... ['queen', 'princess'] word_list[0] queen word_list[1]  princess\n",
      "......i..... 36 ....word_list.... ['queen', 'king'] word_list[0] queen word_list[1]  king\n",
      "......i..... 37 ....word_list.... ['queen', 'rule'] word_list[0] queen word_list[1]  rule\n",
      "......i..... 38 ....word_list.... ['queen', 'realm'] word_list[0] queen word_list[1]  realm\n",
      "......i..... 39 ....word_list.... ['king', 'rule'] word_list[0] king word_list[1]  rule\n",
      "......i..... 40 ....word_list.... ['king', 'queen'] word_list[0] king word_list[1]  queen\n",
      "......i..... 41 ....word_list.... ['king', 'realm'] word_list[0] king word_list[1]  realm\n",
      "......i..... 42 ....word_list.... ['rule', 'realm'] word_list[0] rule word_list[1]  realm\n",
      "......i..... 43 ....word_list.... ['rule', 'king'] word_list[0] rule word_list[1]  king\n",
      "......i..... 44 ....word_list.... ['rule', 'queen'] word_list[0] rule word_list[1]  queen\n",
      "......i..... 45 ....word_list.... ['realm', 'rule'] word_list[0] realm word_list[1]  rule\n",
      "......i..... 46 ....word_list.... ['realm', 'king'] word_list[0] realm word_list[1]  king\n",
      "......i..... 47 ....word_list.... ['realm', 'queen'] word_list[0] realm word_list[1]  queen\n",
      "......i..... 48 ....word_list.... ['prince', 'strong'] word_list[0] prince word_list[1]  strong\n",
      "......i..... 49 ....word_list.... ['prince', 'man'] word_list[0] prince word_list[1]  man\n",
      "......i..... 50 ....word_list.... ['strong', 'man'] word_list[0] strong word_list[1]  man\n",
      "......i..... 51 ....word_list.... ['strong', 'prince'] word_list[0] strong word_list[1]  prince\n",
      "......i..... 52 ....word_list.... ['man', 'strong'] word_list[0] man word_list[1]  strong\n",
      "......i..... 53 ....word_list.... ['man', 'prince'] word_list[0] man word_list[1]  prince\n",
      "......i..... 54 ....word_list.... ['princess', 'beautiful'] word_list[0] princess word_list[1]  beautiful\n",
      "......i..... 55 ....word_list.... ['princess', 'woman'] word_list[0] princess word_list[1]  woman\n",
      "......i..... 56 ....word_list.... ['beautiful', 'woman'] word_list[0] beautiful word_list[1]  woman\n",
      "......i..... 57 ....word_list.... ['beautiful', 'princess'] word_list[0] beautiful word_list[1]  princess\n",
      "......i..... 58 ....word_list.... ['woman', 'beautiful'] word_list[0] woman word_list[1]  beautiful\n",
      "......i..... 59 ....word_list.... ['woman', 'princess'] word_list[0] woman word_list[1]  princess\n",
      "......i..... 60 ....word_list.... ['royal', 'family'] word_list[0] royal word_list[1]  family\n",
      "......i..... 61 ....word_list.... ['royal', 'king'] word_list[0] royal word_list[1]  king\n",
      "......i..... 62 ....word_list.... ['royal', 'queen'] word_list[0] royal word_list[1]  queen\n",
      "......i..... 63 ....word_list.... ['family', 'king'] word_list[0] family word_list[1]  king\n",
      "......i..... 64 ....word_list.... ['family', 'royal'] word_list[0] family word_list[1]  royal\n",
      "......i..... 65 ....word_list.... ['family', 'queen'] word_list[0] family word_list[1]  queen\n",
      "......i..... 66 ....word_list.... ['family', 'their'] word_list[0] family word_list[1]  their\n",
      "......i..... 67 ....word_list.... ['king', 'queen'] word_list[0] king word_list[1]  queen\n",
      "......i..... 68 ....word_list.... ['king', 'family'] word_list[0] king word_list[1]  family\n",
      "......i..... 69 ....word_list.... ['king', 'their'] word_list[0] king word_list[1]  their\n",
      "......i..... 70 ....word_list.... ['king', 'royal'] word_list[0] king word_list[1]  royal\n",
      "......i..... 71 ....word_list.... ['king', 'children'] word_list[0] king word_list[1]  children\n",
      "......i..... 72 ....word_list.... ['queen', 'their'] word_list[0] queen word_list[1]  their\n",
      "......i..... 73 ....word_list.... ['queen', 'king'] word_list[0] queen word_list[1]  king\n",
      "......i..... 74 ....word_list.... ['queen', 'children'] word_list[0] queen word_list[1]  children\n",
      "......i..... 75 ....word_list.... ['queen', 'family'] word_list[0] queen word_list[1]  family\n",
      "......i..... 76 ....word_list.... ['queen', 'royal'] word_list[0] queen word_list[1]  royal\n",
      "......i..... 77 ....word_list.... ['their', 'children'] word_list[0] their word_list[1]  children\n",
      "......i..... 78 ....word_list.... ['their', 'queen'] word_list[0] their word_list[1]  queen\n",
      "......i..... 79 ....word_list.... ['their', 'king'] word_list[0] their word_list[1]  king\n",
      "......i..... 80 ....word_list.... ['their', 'family'] word_list[0] their word_list[1]  family\n",
      "......i..... 81 ....word_list.... ['children', 'their'] word_list[0] children word_list[1]  their\n",
      "......i..... 82 ....word_list.... ['children', 'queen'] word_list[0] children word_list[1]  queen\n",
      "......i..... 83 ....word_list.... ['children', 'king'] word_list[0] children word_list[1]  king\n",
      "......i..... 84 ....word_list.... ['prince', 'only'] word_list[0] prince word_list[1]  only\n",
      "......i..... 85 ....word_list.... ['prince', 'boy'] word_list[0] prince word_list[1]  boy\n",
      "......i..... 86 ....word_list.... ['prince', 'now'] word_list[0] prince word_list[1]  now\n",
      "......i..... 87 ....word_list.... ['only', 'boy'] word_list[0] only word_list[1]  boy\n",
      "......i..... 88 ....word_list.... ['only', 'prince'] word_list[0] only word_list[1]  prince\n",
      "......i..... 89 ....word_list.... ['only', 'now'] word_list[0] only word_list[1]  now\n",
      "......i..... 90 ....word_list.... ['boy', 'now'] word_list[0] boy word_list[1]  now\n",
      "......i..... 91 ....word_list.... ['boy', 'only'] word_list[0] boy word_list[1]  only\n",
      "......i..... 92 ....word_list.... ['boy', 'prince'] word_list[0] boy word_list[1]  prince\n",
      "......i..... 93 ....word_list.... ['now', 'boy'] word_list[0] now word_list[1]  boy\n",
      "......i..... 94 ....word_list.... ['now', 'only'] word_list[0] now word_list[1]  only\n",
      "......i..... 95 ....word_list.... ['now', 'prince'] word_list[0] now word_list[1]  prince\n",
      "......i..... 96 ....word_list.... ['boy', 'man'] word_list[0] boy word_list[1]  man\n",
      "......i..... 97 ....word_list.... ['man', 'boy'] word_list[0] man word_list[1]  boy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 21:24:38.140825: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 242, in call  **\n        y_pred, y_true = losses_utils.squeeze_or_expand_dimensions(y_pred, y_true)\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/utils/losses_utils.py\", line 187, in squeeze_or_expand_dimensions\n        y_true, y_pred = remove_squeezable_dimensions(\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/utils/losses_utils.py\", line 117, in remove_squeezable_dimensions\n        labels = tf.convert_to_tensor(labels)\n\n    TypeError: Failed to convert elements of SparseTensor(indices=Tensor(\"DeserializeSparse_1:0\", shape=(None, 2), dtype=int64), values=Tensor(\"DeserializeSparse_1:1\", shape=(None,), dtype=float32), dense_shape=Tensor(\"stack_1:0\", shape=(2,), dtype=int64)) to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3w/qgrjz9016jd1t5gx01np29gw0000gn/T/ipykernel_6331/2685402581.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m# Optimizing the network weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 242, in call  **\n        y_pred, y_true = losses_utils.squeeze_or_expand_dimensions(y_pred, y_true)\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/utils/losses_utils.py\", line 187, in squeeze_or_expand_dimensions\n        y_true, y_pred = remove_squeezable_dimensions(\n    File \"/Users/dms/opt/anaconda3/lib/python3.9/site-packages/keras/utils/losses_utils.py\", line 117, in remove_squeezable_dimensions\n        labels = tf.convert_to_tensor(labels)\n\n    TypeError: Failed to convert elements of SparseTensor(indices=Tensor(\"DeserializeSparse_1:0\", shape=(None, 2), dtype=int64), values=Tensor(\"DeserializeSparse_1:1\", shape=(None,), dtype=float32), dense_shape=Tensor(\"stack_1:0\", shape=(2,), dtype=int64)) to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Drawing the embeddings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep learning: \n",
    "from keras.models import Input, Model\n",
    "from keras.layers import Dense\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "# Custom functions\n",
    "#from utility import text_preprocessing, create_unique_word_dict\n",
    "\n",
    "# Reading the text from the input folder\n",
    "texts = pd.read_csv('input/sample.csv')\n",
    "texts = [x for x in texts['text']]\n",
    "\n",
    "# Defining the window for context\n",
    "window = 2\n",
    "\n",
    "# Creating a placeholder for the scanning of the word list\n",
    "word_lists = []\n",
    "all_text = []\n",
    "\n",
    "for text in texts:\n",
    "\n",
    "    # Cleaning the text\n",
    "    text = text_preprocessing(text)\n",
    "    print(text)\n",
    "    # Appending to the all text list\n",
    "    all_text += text \n",
    "\n",
    "    # Creating a context dictionary\n",
    "    for i, word in enumerate(text):\n",
    "        print(\"......i.....\" ,i,\"....word....\",word)\n",
    "        for w in range(3):\n",
    "            print(w)\n",
    "            # Getting the context that is ahead by *window* words\n",
    "            if i + 1 + w < len(text): \n",
    "                word_lists.append([word] + [text[(i + 1 + w)]])\n",
    "            # Getting the context that is behind by *window* words    \n",
    "            if i - w - 1 >= 0:\n",
    "                word_lists.append([word] + [text[(i - w - 1)]])\n",
    "\n",
    "                \n",
    "print(\"word list \" , word_lists)\n",
    "unique_word_dict = create_unique_word_dict(all_text)\n",
    "print(\"unique_word_dict\",unique_word_dict)\n",
    "\n",
    "# Defining the number of features (unique words)\n",
    "n_words = len(unique_word_dict)\n",
    "\n",
    "# Getting all the unique words \n",
    "words = list(unique_word_dict.keys())\n",
    "\n",
    "print(\"words\",words)\n",
    "\n",
    "# Creating the X and Y matrices using one hot encoding\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i, word_list in tqdm(enumerate(word_lists)):\n",
    "    # Getting the indices\n",
    "    \n",
    "    main_word_index = unique_word_dict.get(word_list[0])\n",
    "    context_word_index = unique_word_dict.get(word_list[1])\n",
    "    print(\"......i.....\" ,i,\"....word_list....\",word_list , \"word_list[0]\",word_list[0],\"word_list[1] \",word_list[1])\n",
    "    # Creating the placeholders   \n",
    "    X_row = np.zeros(n_words)\n",
    "    Y_row = np.zeros(n_words)\n",
    "\n",
    "    # One hot encoding the main word\n",
    "    X_row[main_word_index] = 1\n",
    "\n",
    "    # One hot encoding the Y matrix words \n",
    "    Y_row[context_word_index] = 1\n",
    "\n",
    "    # Appending to the main matrices\n",
    "    X.append(X_row)\n",
    "    Y.append(Y_row)\n",
    "\n",
    "# Converting the matrices into a sparse format because the vast majority of the data are 0s\n",
    "X = sparse.csr_matrix(X)\n",
    "Y = sparse.csr_matrix(Y)\n",
    "\n",
    "# Defining the size of the embedding\n",
    "embed_size = 2\n",
    "\n",
    "# Defining the neural network\n",
    "inp = Input(shape=(X.shape[1],))\n",
    "x = Dense(units=embed_size, activation='linear')(inp)\n",
    "x = Dense(units=Y.shape[1], activation='softmax')(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "\n",
    "# Optimizing the network weights\n",
    "model.fit(\n",
    "    x=X, \n",
    "    y=Y, \n",
    "    batch_size=256,\n",
    "    epochs=1000\n",
    "    )\n",
    "\n",
    "# Obtaining the weights from the neural network. \n",
    "# These are the so called word embeddings\n",
    "\n",
    "# The input layer \n",
    "weights = model.get_weights()[0]\n",
    "\n",
    "# Creating a dictionary to store the embeddings in. The key is a unique word and \n",
    "# the value is the numeric vector\n",
    "embedding_dict = {}\n",
    "for word in words: \n",
    "    embedding_dict.update({\n",
    "        word: weights[unique_word_dict.get(word)]\n",
    "        })\n",
    "\n",
    "# Ploting the embeddings\n",
    "plt.figure(figsize=(10, 10))\n",
    "for word in list(unique_word_dict.keys()):\n",
    "    coord = embedding_dict.get(word)\n",
    "    plt.scatter(coord[0], coord[1])\n",
    "    plt.annotate(word, (coord[0], coord[1]))       \n",
    "\n",
    "# Saving the embedding vector to a txt file\n",
    "try:\n",
    "    os.mkdir(f'{os.getcwd()}\\\\output')        \n",
    "except Exception as e:\n",
    "    print(f'Cannot create output folder: {e}')\n",
    "\n",
    "with open(f'{os.getcwd()}\\\\output\\\\embedding.txt', 'w') as f:\n",
    "    for key, value in embedding_dict.items():\n",
    "        try:\n",
    "            f.write(f'{key}: {value}\\n')   \n",
    "        except Exception as e:\n",
    "            print(f'Cannot write word {key} to dict: {e}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3w/qgrjz9016jd1t5gx01np29gw0000gn/T/ipykernel_6173/3929920021.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_dict' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.18738952, -0.37835294],\n",
       "       [ 0.2355836 ,  0.33867437],\n",
       "       [-0.15907553,  0.39721954],\n",
       "       [ 0.4589963 ,  0.08188581],\n",
       "       [-0.38270926,  0.12757683],\n",
       "       [ 0.2276771 ,  0.06439   ],\n",
       "       [ 0.43437314,  0.0524224 ],\n",
       "       [ 0.10861504,  0.12535983],\n",
       "       [-0.0515455 , -0.14022624],\n",
       "       [-0.4143938 ,  0.41141826],\n",
       "       [-0.22932553, -0.16115797],\n",
       "       [ 0.36094117, -0.02135694],\n",
       "       [-0.12745845,  0.10817689],\n",
       "       [-0.03604123, -0.36303377],\n",
       "       [-0.07821628, -0.06119713],\n",
       "       [-0.41177335,  0.26991826],\n",
       "       [-0.49090514, -0.0929864 ],\n",
       "       [ 0.21016878, -0.00394106],\n",
       "       [-0.4260587 , -0.29772568],\n",
       "       [ 0.0184477 ,  0.07268143],\n",
       "       [-0.10561186, -0.43330798]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beautiful': 0,\n",
       " 'boy': 1,\n",
       " 'can': 2,\n",
       " 'children': 3,\n",
       " 'daughter': 4,\n",
       " 'family': 5,\n",
       " 'future': 6,\n",
       " 'king': 7,\n",
       " 'man': 8,\n",
       " 'now': 9,\n",
       " 'only': 10,\n",
       " 'prince': 11,\n",
       " 'princess': 12,\n",
       " 'queen': 13,\n",
       " 'realm': 14,\n",
       " 'royal': 15,\n",
       " 'rule': 16,\n",
       " 'son': 17,\n",
       " 'strong': 18,\n",
       " 'their': 19,\n",
       " 'woman': 20}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[['future', 'king'], ['future', 'prince'], ['king', 'prince'], ['king', 'future'], \n",
    "  ['prince', 'king'], ['prince', 'future'], ['daughter', 'princess'], ['princess', 'daughter'],\n",
    "  ['son', 'prince'], ['prince', 'son'], ['only', 'man'], ['only', 'can'], ['only', 'king'], ['man', 'can'],\n",
    "  ['man', 'only'], ['man', 'king'], ['can', 'king'], ['can', 'man'], ['can', 'only'], ['king', 'can'], ['king', 'man'],\n",
    "  ['king', 'only'], ['only', 'woman'], ['only', 'can'], ['only', 'queen'], ['woman', 'can'], ['woman', 'only'], \n",
    "  ['woman', 'queen'], ['can', 'queen'], ['can', 'woman'], ['can', 'only'], ['queen', 'can'], ['queen', 'woman'], \n",
    "  ['queen', 'only'], ['princess', 'queen'], ['queen', 'princess'], ['queen', 'king'], ['queen', 'rule'],\n",
    "  ['queen', 'realm'], ['king', 'rule'], ['king', 'queen'], ['king', 'realm'], ['rule', 'realm'], \n",
    "  ['rule', 'king'], ['rule', 'queen'], ['realm', 'rule'], ['realm', 'king'], ['realm', 'queen'], ['prince', 'strong'], \n",
    "  ['prince', 'man'], ['strong', 'man'], ['strong', 'prince'], ['man', 'strong'], ['man', 'prince'], \n",
    "  ['princess', 'beautiful'], ['princess', 'woman'], ['beautiful', 'woman'], ['beautiful', 'princess'],\n",
    "  ['woman', 'beautiful'], ['woman', 'princess'], ['royal', 'family'], ['royal', 'king'], ['royal', 'queen'], \n",
    "  ['family', 'king'], ['family', 'royal'], ['family', 'queen'], ['family', 'their'], ['king', 'queen'], \n",
    "  ['king', 'family'], ['king', 'their'], ['king', 'royal'], ['king', 'children'], ['queen', 'their'], ['queen', 'king'],\n",
    "  ['queen', 'children'], ['queen', 'family'], ['queen', 'royal'], ['their', 'children'], ['their', 'queen'],\n",
    "  ['their', 'king'], ['their', 'family'], ['children', 'their'], ['children', 'queen'], ['children', 'king'],\n",
    "  ['prince', 'only'], ['prince', 'boy'], ['prince', 'now'], ['only', 'boy'], ['only', 'prince'], ['only', 'now'],\n",
    "  ['boy', 'now'], ['boy', 'only'], ['boy', 'prince'], ['now', 'boy'], ['now', 'only'], ['now', 'prince'], \n",
    "  ['boy', 'man'], ['man', 'boy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['future', 'king'],\n",
       " ['future', 'prince'],\n",
       " ['king', 'prince'],\n",
       " ['king', 'future'],\n",
       " ['prince', 'king'],\n",
       " ['prince', 'future'],\n",
       " ['daughter', 'princess'],\n",
       " ['princess', 'daughter'],\n",
       " ['son', 'prince'],\n",
       " ['prince', 'son'],\n",
       " ['only', 'man'],\n",
       " ['only', 'can'],\n",
       " ['only', 'king'],\n",
       " ['man', 'can'],\n",
       " ['man', 'only'],\n",
       " ['man', 'king'],\n",
       " ['can', 'king'],\n",
       " ['can', 'man'],\n",
       " ['can', 'only'],\n",
       " ['king', 'can'],\n",
       " ['king', 'man'],\n",
       " ['king', 'only'],\n",
       " ['only', 'woman'],\n",
       " ['only', 'can'],\n",
       " ['only', 'queen'],\n",
       " ['woman', 'can'],\n",
       " ['woman', 'only'],\n",
       " ['woman', 'queen'],\n",
       " ['can', 'queen'],\n",
       " ['can', 'woman'],\n",
       " ['can', 'only'],\n",
       " ['queen', 'can'],\n",
       " ['queen', 'woman'],\n",
       " ['queen', 'only'],\n",
       " ['princess', 'queen'],\n",
       " ['queen', 'princess'],\n",
       " ['queen', 'king'],\n",
       " ['queen', 'rule'],\n",
       " ['queen', 'realm'],\n",
       " ['king', 'rule'],\n",
       " ['king', 'queen'],\n",
       " ['king', 'realm'],\n",
       " ['rule', 'realm'],\n",
       " ['rule', 'king'],\n",
       " ['rule', 'queen'],\n",
       " ['realm', 'rule'],\n",
       " ['realm', 'king'],\n",
       " ['realm', 'queen'],\n",
       " ['prince', 'strong'],\n",
       " ['prince', 'man'],\n",
       " ['strong', 'man'],\n",
       " ['strong', 'prince'],\n",
       " ['man', 'strong'],\n",
       " ['man', 'prince'],\n",
       " ['princess', 'beautiful'],\n",
       " ['princess', 'woman'],\n",
       " ['beautiful', 'woman'],\n",
       " ['beautiful', 'princess'],\n",
       " ['woman', 'beautiful'],\n",
       " ['woman', 'princess'],\n",
       " ['royal', 'family'],\n",
       " ['royal', 'king'],\n",
       " ['royal', 'queen'],\n",
       " ['family', 'king'],\n",
       " ['family', 'royal'],\n",
       " ['family', 'queen'],\n",
       " ['family', 'their'],\n",
       " ['king', 'queen'],\n",
       " ['king', 'family'],\n",
       " ['king', 'their'],\n",
       " ['king', 'royal'],\n",
       " ['king', 'children'],\n",
       " ['queen', 'their'],\n",
       " ['queen', 'king'],\n",
       " ['queen', 'children'],\n",
       " ['queen', 'family'],\n",
       " ['queen', 'royal'],\n",
       " ['their', 'children'],\n",
       " ['their', 'queen'],\n",
       " ['their', 'king'],\n",
       " ['their', 'family'],\n",
       " ['children', 'their'],\n",
       " ['children', 'queen'],\n",
       " ['children', 'king'],\n",
       " ['prince', 'only'],\n",
       " ['prince', 'boy'],\n",
       " ['prince', 'now'],\n",
       " ['only', 'boy'],\n",
       " ['only', 'prince'],\n",
       " ['only', 'now'],\n",
       " ['boy', 'now'],\n",
       " ['boy', 'only'],\n",
       " ['boy', 'prince'],\n",
       " ['now', 'boy'],\n",
       " ['now', 'only'],\n",
       " ['now', 'prince'],\n",
       " ['boy', 'man'],\n",
       " ['man', 'boy'],\n",
       " ['man', 'h'],\n",
       " ['P', 'r'],\n",
       " ['P', 'i'],\n",
       " ['P', 'n'],\n",
       " ['r', 'i'],\n",
       " ['r', 'P'],\n",
       " ['r', 'n'],\n",
       " ['r', 'c'],\n",
       " ['i', 'n'],\n",
       " ['i', 'r'],\n",
       " ['i', 'c'],\n",
       " ['i', 'P'],\n",
       " ['i', 'e'],\n",
       " ['n', 'c'],\n",
       " ['n', 'i'],\n",
       " ['n', 'e'],\n",
       " ['n', 'r'],\n",
       " ['n', 'P'],\n",
       " ['c', 'e'],\n",
       " ['c', 'n'],\n",
       " ['c', 'i'],\n",
       " ['c', 'r'],\n",
       " ['e', 'c'],\n",
       " ['e', 'n'],\n",
       " ['e', 'i']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......i..... 0 ....word.... P\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 1 ....word.... r\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 2 ....word.... i\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 3 ....word.... n\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 4 ....word.... c\n",
      "0\n",
      "1\n",
      "2\n",
      "......i..... 5 ....word.... e\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "text='Prince'\n",
    "for i, word in enumerate(text):\n",
    "        print(\"......i.....\" ,i,\"....word....\",word)\n",
    "        for w in range(3):\n",
    "            print(w)\n",
    "            # Getting the context that is ahead by *window* words\n",
    "            if i + 1 + w < len(text): \n",
    "                word_lists.append([word] + [text[(i + 1 + w)]])\n",
    "            # Getting the context that is behind by *window* words    \n",
    "            if i - w - 1 >= 0:\n",
    "                word_lists.append([word] + [text[(i - w - 1)]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
